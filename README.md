DistilBert for Chinese 海量中文预训练蒸馏Bert模型

12月16日发布 target to release on Dec 16th.

发布内容 Contents：

1. 可下载的蒸馏模型，已经训练过 

a pretrained chinese DistilBert, others can use it directly or  trained again on their own corpus; 

2. 可用于下游任务的例子和代码，包括3个ChineseGLUE(CLUE)的任务 

fine tuning examples and codes using DistilBert on three ChineseGLUE(CLUE) tasks; 

3. 小模型基准测评

performance comparsion with albert_tiny, ernie_tiny.

Join with us on chineseGLUE#163.com
